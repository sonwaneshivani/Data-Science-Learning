{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to do :\n",
    "1. How to do scrapping\n",
    "2. How to build an application\n",
    "3. How to do deployment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creatting flipkart var & some info\n",
    "Ex: We are taking flipkart website here and there are many products out  of that i want to buy something for ex: think iphone. and i cannot see and checks for all dffrnt iphone products. So, we try to see reviews. \n",
    "* Here we are trying to scrap data and build a sentiment analyser\n",
    "1. frstly we have to acquire data in order to build complete sentiment analyzer for particular product in ML Session\n",
    "2. Here we are learning how to acquire data from some website not from my system.\n",
    "3. How and what we do  :\n",
    "* We go and search in search bar for some product & it does send the search string in url to server\n",
    "* And server tries to rply back with relevant data \n",
    "4. we take the url after searching & then we can try to create a var \n",
    "* What it basically does is try to put the string appended by us in the search bar of flipkart\n",
    "* It simply means we are trying to parameterized that\n",
    "* So, whenever we try to create an app, we try to create a web page as input and try to pass the string\n",
    "* We can also keep string as TV\n",
    "5. When we click on one of the product we can see reviews,description and comments available for that available product at that place."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Objective for today's class\n",
    "* We are supposed to write python code \n",
    "* which will be able to execute this url and we can land on that page and \n",
    "* then we can click and get on the product one by one and then we are supposed to scrap reviews one by one wrto that product"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### opening of url without clicking\n",
    "* by urlopen()\n",
    "* urlclient.read() - gives whole html code\n",
    "* We can get into product detail page by using hyperlink(href - we can find it by using developers tools as well)\n",
    "* But we are getting the href in automated way\n",
    "1. Go to developers section > choose one box > copy the class there and paste in find_all"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deleting 3 big boxs\n",
    "* bcoz it compromises of headers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To get particular product\n",
    "* We need href\n",
    "1. select one bigbox frst as div.div.div.div\n",
    "2. We can handle the error with exception handling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To extract Comments, Name, description_review\n",
    "1. requests.get(prodlink) - it will try to scrap the whole page of that product"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarly we can scrap every information available on python"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
